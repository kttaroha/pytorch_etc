{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch \n",
    "from torch import optim\n",
    "import sys \n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from models.resnet import *\n",
    "import socket\n",
    "\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10の準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/\"\n",
    "cifar10_train = datasets.CIFAR10(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
    "cifar10_test = datasets.CIFAR10(data_path, train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = cifar10_train[99]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1553cd0599b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imageのaugumentationや正規化を実施した上で、再度cifar10を読み込む\n",
    "- 学習データセットのチャネルごとの平均と標準偏差を用いて、学習データセット、テストデータセットの両方を正規化\n",
    "- テストデータセットではaugumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_stack = torch.stack([img_t for img_t, _ in cifar10_train])\n",
    "mean_train = train_img_stack.view(3, -1).mean(dim=1)\n",
    "std_train = train_img_stack.view(3, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean_train, std_train)\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean_train, std_train)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "cifar10_train_dataset_aug = datasets.CIFAR10(data_path, train=True, download=True, transform=transforms_train)\n",
    "cifar10_test_dataset = datasets.CIFAR10(data_path, train=False, download=True, transform=transforms_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaderを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_train_dataloader = DataLoader(cifar10_train_dataset_aug, batch_size=64, shuffle=True)\n",
    "cifar10_test_dataloader = DataLoader(cifar10_test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習用のセットアップを行う\n",
    "- モデルの定義\n",
    "- 損失関数の定義\n",
    "- Optimizerの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "# モデルの定義\n",
    "resnet18 = ResNet(BasicBlock, [2, 2, 2, 2], 10)\n",
    "resnet18.to(device=device)\n",
    "# 損失関数の定義\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# Optimizerの定義\n",
    "optimizer = optim.SGD(resnet18.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loss_fn, train_dataloader, test_dataloader, n_epochs):\n",
    "    model.train()\n",
    "    for n_epoch in range(n_epochs):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_dataloader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "    \n",
    "        \n",
    "        print(f'{datetime.datetime.now()} Epoch {n_epoch}, Training loss {loss_train / len(train_dataloader.dataset)}')\n",
    "        eval_model(model, test_dataloader)\n",
    "    return model\n",
    "\n",
    "\n",
    "def eval_model(model, test_dataloader):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    for imgs, labels in test_dataloader:\n",
    "        imgs = imgs.to(device=device)\n",
    "        labels = labels.to(device=device)\n",
    "        outputs = model(imgs)\n",
    "        num_correct += sum(outputs.argmax(axis=1) == labels).item()\n",
    "    \n",
    "    print(f\"Accuracy {num_correct / len(test_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-25 23:23:55.374997 Epoch 0, Training loss 0.030016513109207152\n",
      "Accuracy 0.3783\n",
      "2022-09-25 23:24:30.263080 Epoch 1, Training loss 0.027630066032409667\n",
      "Accuracy 0.3546\n",
      "2022-09-25 23:25:05.166485 Epoch 2, Training loss 0.02436999591588974\n",
      "Accuracy 0.3847\n",
      "2022-09-25 23:25:39.978515 Epoch 3, Training loss 0.02282743285894394\n",
      "Accuracy 0.4173\n",
      "2022-09-25 23:26:14.797814 Epoch 4, Training loss 0.021661278488636016\n",
      "Accuracy 0.4864\n",
      "2022-09-25 23:26:49.608673 Epoch 5, Training loss 0.020636741350889207\n",
      "Accuracy 0.4246\n",
      "2022-09-25 23:27:24.385447 Epoch 6, Training loss 0.019754293645620345\n",
      "Accuracy 0.4822\n",
      "2022-09-25 23:27:59.160464 Epoch 7, Training loss 0.018988832066059114\n",
      "Accuracy 0.4835\n",
      "2022-09-25 23:28:33.948881 Epoch 8, Training loss 0.018258316884040834\n",
      "Accuracy 0.3638\n",
      "2022-09-25 23:29:08.785098 Epoch 9, Training loss 0.017665082203149794\n",
      "Accuracy 0.5599\n",
      "2022-09-25 23:29:43.557656 Epoch 10, Training loss 0.017054505878686906\n",
      "Accuracy 0.5683\n",
      "2022-09-25 23:30:18.351506 Epoch 11, Training loss 0.016518129703998567\n",
      "Accuracy 0.6253\n",
      "2022-09-25 23:30:53.127588 Epoch 12, Training loss 0.015958960835933685\n",
      "Accuracy 0.6224\n",
      "2022-09-25 23:31:27.887613 Epoch 13, Training loss 0.015494141937494278\n",
      "Accuracy 0.6555\n",
      "2022-09-25 23:32:02.627911 Epoch 14, Training loss 0.015144522963762284\n",
      "Accuracy 0.6514\n",
      "2022-09-25 23:32:37.387844 Epoch 15, Training loss 0.014758165783882142\n",
      "Accuracy 0.5915\n",
      "2022-09-25 23:33:12.187532 Epoch 16, Training loss 0.014352882353067397\n",
      "Accuracy 0.6463\n",
      "2022-09-25 23:33:46.978679 Epoch 17, Training loss 0.01400699805378914\n",
      "Accuracy 0.5981\n",
      "2022-09-25 23:34:21.744896 Epoch 18, Training loss 0.013676689012050628\n",
      "Accuracy 0.6032\n",
      "2022-09-25 23:34:56.546523 Epoch 19, Training loss 0.013413407707214355\n",
      "Accuracy 0.648\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(resnet18, optimizer, loss_fn, cifar10_train_dataloader, cifar10_test_dataloader, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 複数GPUでの学習ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験\n",
    "def example(rank, world_size):\n",
    "    # create default process group\n",
    "    dist.init_process_group(\"gloo/\", rank=rank, world_size=world_size)\n",
    "    # create local model\n",
    "    model = nn.Linear(10, 10).to(rank)\n",
    "    # construct DDP model\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "    # define loss function and optimizer\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    # forward pass\n",
    "    outputs = ddp_model(torch.randn(20, 10).to(rank))\n",
    "    labels = torch.randn(20, 10).to(rank)\n",
    "    # backward pass\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "def main():\n",
    "    world_size = 2\n",
    "    mp.spawn(example,\n",
    "        args=(world_size,),\n",
    "        nprocs=world_size,\n",
    "        join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "process 1 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a823c7567325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MASTER_ADDR\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"spcc-a40g13\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"MASTER_PORT\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"29500\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-0a8ca2cd91b1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         join=True)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    198\u001b[0m                ' torch.multiprocessing.start_process(...)' % start_method)\n\u001b[1;32m    199\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 raise Exception(\n\u001b[1;32m    112\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: process 1 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "os.environ[\"MASTER_ADDR\"] = \"spcc-a40g13\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_ddp(\n",
    "    rank, world_size, model, loss_fn, optimizer, train_dataloader, test_dataloader, n_epochs):\n",
    "    # create default process group\n",
    "    dist.init_process_group(\"nvcc\", rank=rank, world_size=world_size)\n",
    "    # construct DDP model\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "    # define loss function and optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "    \n",
    "    for n_epoch in range(n_epochs):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_dataloader:\n",
    "            # forward pass\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "    # forward pass\n",
    "    outputs = ddp_model(torch.randn(20, 10).to(rank))\n",
    "    labels = torch.randn(20, 10).to(rank)\n",
    "    # backward pass\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    # update parameters\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
